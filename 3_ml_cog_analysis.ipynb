{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9587ee0b",
   "metadata": {},
   "source": [
    "# Part III\n",
    "Objective: Develop a pipeline for machine learning analysis of speech to assess cognitive function, while critically evaluating model limitations and the need for longitudinal data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1815f9",
   "metadata": {},
   "source": [
    "## Milestones for Today\n",
    "\n",
    "- Extract linguistic features from transcribed speech using both pre-trained deep learning models (GPT) and NLP-based approaches\n",
    "- Train and tune a series of classifiers to detect cognitive state (binary classification)\n",
    "- Evaluate and compare performance metrics on an unseen test set \n",
    "- Discuss challenges, limitations, and research directions: \n",
    "    - Limitations introduced by automatic speech recognition (ASR) errors  \n",
    "    - Importance of feature interpretability for clinical utility\n",
    "    - Generalisability across populations and language domains\n",
    "    - The need for longitudinal data to enable prognostic assessment\n",
    "    - Integration with home-based conversational AI systems for real-world use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfafde9c",
   "metadata": {},
   "source": [
    "### Feature Extraction\n",
    "- Take a look at  examples of transcribed speech from the Cookie Theft picture description task: `./data/ad-example.txt` and `./data/cn-example.txt` \n",
    "- Inspect precomputed LIWC linguistic features (per speech sample): `./data/liwc-ad.csv` - see below Lexical and semantic psycholinguistics\n",
    "- Install required dependencies (check `ml_analysis.ipynb` and `utils_ml_analysis.py`)\n",
    "- Extract additional features: Use the function `text_analysis_features()` (in `ml_analysis.ipynb`) to compute lexical diversity and semantic complexity features (see description below)\n",
    "- Verify input files for model training and evaluation: `train_liwc.pkl` and `test_liwc.pkl`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4674d3",
   "metadata": {},
   "source": [
    "*Lexical and semantic psycholinguistics* ðŸ“–ðŸ‘€\n",
    "\n",
    "Different categories are extracted using LIWC-22 Dictionary, including: word count,\n",
    "summary language variables (e.g., analytical thinking, clout, authenticity, and emotional\n",
    "tone), general descriptor categories (words per sentence, percent of target words\n",
    "captured by the dictionary, and percent of words in the text that are longer than six\n",
    "letters), standard linguistic dimensions (e.g., percentage of words in the text that are\n",
    "pronouns, articles, adverbs, verbs), word categories tapping psychological constructs\n",
    "(e.g., affect, cognition, biological processes, drives) personal concern categories (e.g.,\n",
    "home, leisure activities), informal language markers (assents, fillers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84204cdf",
   "metadata": {},
   "source": [
    "*Lexical diversity and semantic complexity features* ðŸ“–ðŸ‘€\n",
    "- Type-Token Ratio (TTR): The ratio of unique words (types) to total words (tokens) in a transcript, adjusted for text length. Lower TTR indicates less diverse vocabulary usage and less lexical richness\n",
    "- Propositional Idea Density (PID): The number of expressed propositions â€“ distinct facts or notions contained in a text with verbs, adjectives, adverbs, prepositions, and conjunctions â€“ divided by the total number of words. These are considered as part-of-speech (POS) tags derived from NLTK Python toolkit. Lower PID suggests simpler language, while higher PID reflects a greater number of ideas in a concise form.\n",
    "- Brunetâ€™s index: A measure of lexical richness based on the variation in word types (part-of-speech) relative to the total word count. Lower values indicate higher lexical richness\n",
    "- Honoreâ€™s index: A measure of lexical diversity focused on the frequency of hapax legomena (words that appear only once). Lower Honoreâ€™s Index values reflect reduced lexical variety.\n",
    "- Consecutive duplicate words: The proportion of duplicated words/phrases with reference to the total number of words/phrases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20823519",
   "metadata": {},
   "source": [
    "### Predictive Modelling\n",
    "- Create a dictionary of classifiers using `ml.create_models()` and corresponding hyperparameter grids via `ml.create_param_grids()` (see `utils_ml_analysis.py`)\n",
    "- Run 10-fold cross-validation with hyperparameter tuning for each model using `ml.crossval()`. Save best models and results to a subfolder (e.g., ./data/cv_hyperparam_liwc/)\n",
    "- Use `ml.fit_and_evaluate_bootstrap_()` to assess each model on the test set and compute performance metrics with 10 boostrap repeats \n",
    "    - Sensitivity\n",
    "    - Specificity\n",
    "    - ROC-AUC\n",
    "    - Accuracy\n",
    "- Compare performance metrics of best-performing model trained on interpretable NLP features vs. GPT embeddings\n",
    "    - Show results in tabular format for feature set and model selected \n",
    "- Reflect on: \n",
    "    - Interpretability? \n",
    "    - Clinical utility? \n",
    "    - More explainable features could better inform clinicians of linguistic changes indicative of cognitive deterioration. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
